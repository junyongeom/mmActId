{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b6fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "base_directories = [\n",
    "    # put path of pantomime/primary_exp/office(and open)/1/0/normal   \n",
    "]\n",
    "\n",
    "def load_all_pkl_files(base_dirs):\n",
    "    pkl_files = {}  \n",
    "    for base_dir in base_dirs:\n",
    "        if not os.path.exists(base_dir):\n",
    "            print(f\"Warning: {base_dir} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        for user_id in os.listdir(base_dir):\n",
    "            user_path = os.path.join(base_dir, user_id)\n",
    "            if os.path.isdir(user_path): \n",
    "                if user_id not in pkl_files:\n",
    "                    pkl_files[user_id] = {}\n",
    "                \n",
    "                for gesture_id in os.listdir(user_path):\n",
    "                    gesture_path = os.path.join(user_path, gesture_id)\n",
    "                    if os.path.isdir(gesture_path):  \n",
    "                        if gesture_id not in pkl_files[user_id]:\n",
    "                            pkl_files[user_id][gesture_id] = []\n",
    "                        \n",
    "                        for filename in os.listdir(gesture_path):\n",
    "                            if filename.endswith(\".pkl\"):\n",
    "                                file_path = os.path.join(gesture_path, filename)\n",
    "                                try:\n",
    "                                    with open(file_path, \"rb\") as f:\n",
    "                                        data = pickle.load(f, encoding=\"latin1\")  \n",
    "                                        pkl_files[user_id][gesture_id].append(data)\n",
    "                                except (pickle.UnpicklingError, UnicodeDecodeError) as e:\n",
    "                                    print(f\"Error loading {file_path}: {e}\")\n",
    "    return pkl_files\n",
    "\n",
    "loaded_data = load_all_pkl_files(base_directories)\n",
    "\n",
    "for user, gestures in loaded_data.items():\n",
    "    print(f\"User {user}:\")\n",
    "    for gesture, files in gestures.items():\n",
    "        print(f\"  Gesture {gesture}: {len(files)} pkl files loaded\")\n",
    "\n",
    "# labeling\n",
    "def label_data(data):\n",
    "    labeled_data = []\n",
    "    user_label_map = {}  # user_label â†’ user_id mapping\n",
    "    for user_idx, (user_id, gestures) in enumerate(data.items()):\n",
    "        user_label_map[user_idx] = user_id  \n",
    "        for gesture_idx, (gesture_id, files) in enumerate(gestures.items()):\n",
    "            for file_data in files:\n",
    "                labeled_data.append({\n",
    "                    \"user_label\": user_idx,\n",
    "                    \"gesture_label\": int(gesture_id)-1,\n",
    "                    \"data\": file_data\n",
    "                })\n",
    "    return labeled_data, user_label_map\n",
    "\n",
    "labeled_data, user_label_map = label_data(loaded_data)\n",
    "\n",
    "print(f\"Total labeled samples: {len(labeled_data)}\")\n",
    "num_unique_users = len(set(sample['user_label'] for sample in labeled_data))\n",
    "print(f\"num_unique_useres: {num_unique_users}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5905bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "assert \"labeled_data\" in globals(), \"labeled_dataê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € pantomime ë¡œë“œ/label_data ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\"\n",
    "assert isinstance(labeled_data, list) and len(labeled_data) > 0, \"labeled_dataê°€ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "gesture_counts = Counter(int(s[\"gesture_label\"]) for s in labeled_data)\n",
    "\n",
    "print(\"=== Gesture (action) counts ===\")\n",
    "for g in sorted(gesture_counts):\n",
    "    print(f\"gesture {g}: {gesture_counts[g]}\")\n",
    "print(\"TOTAL:\", sum(gesture_counts.values()), \"\\n\")\n",
    "\n",
    "user_counts = Counter(int(s[\"user_label\"]) for s in labeled_data)\n",
    "\n",
    "print(\"=== User counts ===\")\n",
    "has_map = (\"user_label_map\" in globals()) and isinstance(user_label_map, dict)\n",
    "for u in sorted(user_counts):\n",
    "    if has_map and u in user_label_map:\n",
    "        print(f\"user {u} ({user_label_map[u]}): {user_counts[u]}\")\n",
    "    else:\n",
    "        print(f\"user {u}: {user_counts[u]}\")\n",
    "print(\"TOTAL:\", sum(user_counts.values()), \"\\n\")  # 41 users 210~420, 21 gestures 410~440 samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cca8bb",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b9392",
   "metadata": {},
   "source": [
    "PROPOSED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a77943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH CONSTRUCTION #\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "from torch_geometric.data import Data\n",
    "from collections import Counter\n",
    "\n",
    "# =========================\n",
    "# Edge weight params\n",
    "# =========================\n",
    "DIST_WEIGHT = 4\n",
    "\n",
    "def positional_encoding_1d(time_steps, max_time_steps):\n",
    "    return torch.sin(time_steps.clone().detach().float() * (math.pi / max_time_steps)).unsqueeze(1)\n",
    "\n",
    "# =========================\n",
    "# Pantomime sample -> frames(list of (Pi,>=3)) normalize\n",
    "# =========================\n",
    "def _get_x_from_item(item):\n",
    "    x = item.get(\"data\", item)\n",
    "    if isinstance(x, dict):\n",
    "        for k in [\"pos\", \"points\", \"pc\", \"xyz\", \"coords\", \"data\", \"frames\"]:\n",
    "            if k in x:\n",
    "                x = x[k]\n",
    "                break\n",
    "    return x\n",
    "\n",
    "def to_frames_pointlist(x):\n",
    "    \"\"\"\n",
    "    Return: frames (list of np.ndarray), frames[t] shape (Pi, C>=3), float32\n",
    "    Supports:\n",
    "      - list/tuple of frames\n",
    "      - (T,P,C) tensor/ndarray\n",
    "      - (N,C) tensor/ndarray -> single frame\n",
    "      - dict (key search)\n",
    "    \"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        for k in [\"pos\", \"points\", \"pc\", \"xyz\", \"coords\", \"data\", \"frames\"]:\n",
    "            if k in x:\n",
    "                x = x[k]\n",
    "                break\n",
    "\n",
    "    # list of frames\n",
    "    if isinstance(x, (list, tuple)) and len(x) > 0 and (not torch.is_tensor(x)) and (not isinstance(x, np.ndarray)):\n",
    "        frames = []\n",
    "        for fr in x:\n",
    "            if fr is None:\n",
    "                frames.append(np.zeros((0, 3), dtype=np.float32))\n",
    "                continue\n",
    "            if isinstance(fr, dict):\n",
    "                for k in [\"pos\", \"points\", \"pc\", \"xyz\", \"coords\", \"data\"]:\n",
    "                    if k in fr:\n",
    "                        fr = fr[k]\n",
    "                        break\n",
    "            fr = np.asarray(fr, dtype=np.float32)\n",
    "            if fr.ndim != 2 or fr.shape[1] < 3:\n",
    "                frames.append(np.zeros((0, 3), dtype=np.float32))\n",
    "            else:\n",
    "                frames.append(fr)\n",
    "        return frames\n",
    "\n",
    "    x = torch.as_tensor(x, dtype=torch.float32)\n",
    "\n",
    "    # (T,P,C)\n",
    "    if x.ndim == 3 and x.size(-1) >= 3:\n",
    "        return [x[t].detach().cpu().numpy().astype(np.float32) for t in range(x.size(0))]\n",
    "\n",
    "    # (N,C) -> single frame\n",
    "    if x.ndim == 2 and x.size(-1) >= 3:\n",
    "        return [x.detach().cpu().numpy().astype(np.float32)]\n",
    "\n",
    "    raise ValueError(f\"Unsupported x type/shape: type={type(x)} shape={getattr(x, 'shape', None)}\")\n",
    "\n",
    "# =========================\n",
    "# PyG graph generation \n",
    "# =========================\n",
    "def create_pyg_graph(point_data_frames, time_interval=1/24):\n",
    "    start_time = time.time()\n",
    "\n",
    "    global_index = 0\n",
    "    node_features = []\n",
    "    time_step_list = []\n",
    "    edge_index = []\n",
    "    edge_weight = []\n",
    "    node_map = {}\n",
    "\n",
    "    non_empty_steps = [t for t in range(len(point_data_frames)) if len(point_data_frames[t]) > 0]\n",
    "    max_time_steps = max(non_empty_steps) + 1 if non_empty_steps else 1\n",
    "\n",
    "    # nodes\n",
    "    for t in non_empty_steps:\n",
    "        node_map[t] = {}\n",
    "        fr = np.asarray(point_data_frames[t], dtype=np.float32)\n",
    "        for i, p in enumerate(fr):\n",
    "            node_map[t][i] = global_index\n",
    "            node_features.append(p[:3])  # XYZ\n",
    "            time_step_list.append(t)\n",
    "            global_index += 1\n",
    "\n",
    "    if len(node_features) == 0:\n",
    "        empty = Data(\n",
    "            x=torch.zeros((0, 4), dtype=torch.float32),\n",
    "            edge_index=torch.zeros((2, 0), dtype=torch.long),\n",
    "            edge_weight=torch.zeros((0,), dtype=torch.float32),\n",
    "            time_steps=torch.zeros((0,), dtype=torch.long),\n",
    "        )\n",
    "        return empty, time.time() - start_time\n",
    "\n",
    "    node_features = np.array(node_features, dtype=np.float32)\n",
    "\n",
    "    # edges between consecutive non-empty frames (all-to-all)\n",
    "    for step_idx in range(len(non_empty_steps) - 1):\n",
    "        t = non_empty_steps[step_idx]\n",
    "        next_t = non_empty_steps[step_idx + 1]\n",
    "\n",
    "        points_t = np.asarray(point_data_frames[t], dtype=np.float32)\n",
    "        points_next_t = np.asarray(point_data_frames[next_t], dtype=np.float32)\n",
    "        if len(points_t) == 0 or len(points_next_t) == 0:\n",
    "            continue\n",
    "\n",
    "        distances = np.linalg.norm(points_t[:, :3, np.newaxis] - points_next_t[:, :3].T, axis=1)\n",
    "        weights = np.exp(-DIST_WEIGHT * distances)\n",
    "\n",
    "        from_idx, to_idx = np.meshgrid(\n",
    "            np.arange(len(points_t)), np.arange(len(points_next_t)), indexing=\"ij\"\n",
    "        )\n",
    "\n",
    "        from_list = from_idx.flatten().tolist()\n",
    "        to_list   = to_idx.flatten().tolist()\n",
    "        w_list    = weights.flatten().tolist()\n",
    "\n",
    "        for fi, ti, w in zip(from_list, to_list, w_list):\n",
    "            edge_index.append([node_map[t][fi], node_map[next_t][ti]])\n",
    "            edge_weight.append(w)\n",
    "\n",
    "    x = torch.tensor(node_features, dtype=torch.float32)\n",
    "    time_steps_tensor = torch.tensor(time_step_list, dtype=torch.long)\n",
    "    pos_enc = positional_encoding_1d(time_steps_tensor, max_time_steps=max_time_steps)\n",
    "    x = torch.cat([x, pos_enc], dim=1)  # (num_nodes,4)\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).T if len(edge_index) else torch.zeros((2, 0), dtype=torch.long)\n",
    "    edge_weight = torch.tensor(edge_weight, dtype=torch.float32) if len(edge_weight) else torch.zeros((0,), dtype=torch.float32)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_weight=edge_weight, time_steps=time_steps_tensor), (time.time() - start_time)\n",
    "\n",
    "\n",
    "assert \"labeled_data\" in globals() and isinstance(labeled_data, list) and len(labeled_data) > 0, \\\n",
    "    \"no labeld data.\"\n",
    "\n",
    "filtered_graphs = []\n",
    "execution_times = []\n",
    "filtered_g_labels = []\n",
    "filtered_u_labels = []\n",
    "\n",
    "for item in labeled_data:\n",
    "    x_raw = _get_x_from_item(item)\n",
    "    frames = to_frames_pointlist(x_raw)\n",
    "\n",
    "    graph, exec_time = create_pyg_graph(frames)\n",
    "\n",
    "    action_label = int(item[\"gesture_label\"])  # 0..20\n",
    "    user_label   = int(item[\"user_label\"])     # 0..40\n",
    "\n",
    "    graph.y_action = torch.tensor([action_label], dtype=torch.long)\n",
    "    graph.y_user   = torch.tensor([user_label], dtype=torch.long)\n",
    "\n",
    "    filtered_graphs.append(graph)\n",
    "    execution_times.append(exec_time)\n",
    "    filtered_g_labels.append(action_label)\n",
    "    filtered_u_labels.append(user_label)\n",
    "\n",
    "avg_time = float(np.mean(execution_times)) if execution_times else 0.0\n",
    "print(f\"ðŸ“Œ Total graphs: {len(filtered_graphs)}\")\n",
    "print(f\"ðŸ“Œ Avg Preprocessing time: {avg_time:.4f} sec\")\n",
    "\n",
    "act_cnt = Counter(filtered_g_labels)\n",
    "usr_cnt = Counter(filtered_u_labels)\n",
    "print(f\"ðŸ“Œ num act: {len(act_cnt)} | ex: {act_cnt.most_common(5)}\")\n",
    "print(f\"ðŸ“Œ num user: {len(usr_cnt)} | ex: {usr_cnt.most_common(5)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f595849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.data import Data\n",
    "import math\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_channels, out_channels)\n",
    "        self.bn1 = nn.LayerNorm(out_channels)\n",
    "        self.fc2 = nn.Linear(out_channels, out_channels)\n",
    "        self.bn2 = nn.LayerNorm(out_channels)\n",
    "        self.relu = nn.ReLU() \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.relu(self.bn2(self.fc2(x))) \n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomGINConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, nn_model, eps=0, train_eps=False):\n",
    "        super(CustomGINConv, self).__init__(aggr=\"add\")  \n",
    "        self.nn = nn_model\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([eps])) if train_eps else eps\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        src, dst = edge_index \n",
    "        weighted_messages = x[src] * edge_weight.view(-1, 1)\n",
    "        aggregated = torch.zeros_like(x, dtype=torch.float32)\n",
    "        aggregated.index_add_(0, dst, weighted_messages.to(dtype=torch.float32)) \n",
    "        # GIN aggregation\n",
    "        out = x.to(dtype=torch.float32) + aggregated\n",
    "        out = self.nn(out)  \n",
    "        return out.to(x.dtype)  \n",
    "\n",
    "class ReadoutWithMLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_hidden_layers=2, method=\"sum\"):\n",
    "        \"\"\"\n",
    "        Readout + MLP \n",
    "        Args:\n",
    "            method: \"sum\", \"mean\", \"max\", \"sum+mean\", \"sum+max\", \"mean+max\", \"sum+mean+max\", \"std\"\n",
    "        \"\"\"\n",
    "        super(ReadoutWithMLP, self).__init__()\n",
    "        self.method = method.lower().split(\"+\")  \n",
    "        self.supported = {'sum', 'mean', 'max', 'std'}\n",
    "        assert set(self.method).issubset(self.supported), f\"not supported Readout: {self.method}\"\n",
    "\n",
    "        self.readout_dim = input_dim * len(self.method)\n",
    "        ###\n",
    "        # if num_hidden_layers > 0:\n",
    "        #     step = (output_dim // self.readout_dim) ** (1 / num_hidden_layers)\n",
    "        #     hidden_dims = [int(self.readout_dim * (step**i)) for i in range(1, num_hidden_layers)]\n",
    "        #     hidden_dims.append(output_dim)\n",
    "        # else:\n",
    "        #     hidden_dims = [output_dim]\n",
    "        ###\n",
    "        hidden_dims = [256, 1024] ####\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = self.readout_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = hidden_dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, output, batch_idx, valid_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            output: (num_nodes, feature_dim)\n",
    "            batch_idx: (num_nodes,) \n",
    "            valid_mask: (num_nodes,) \n",
    "        \"\"\"\n",
    "        batch_size = batch_idx.max().item() + 1\n",
    "        stats = []\n",
    "\n",
    "        for stat in self.method:\n",
    "            stat_embed = torch.zeros((batch_size, output.size(1)), device=output.device)\n",
    "            for i in range(batch_size):\n",
    "                mask = (batch_idx == i)\n",
    "                if valid_mask is not None:\n",
    "                    mask = mask & valid_mask  \n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "                if stat == \"sum\":\n",
    "                    stat_embed[i] = output[mask].sum(dim=0)\n",
    "                elif stat == \"mean\":\n",
    "                    stat_embed[i] = output[mask].mean(dim=0)\n",
    "                elif stat == \"max\":\n",
    "                    stat_embed[i], _ = output[mask].max(dim=0)\n",
    "                elif stat == \"std\":\n",
    "                    stat_embed[i] = output[mask].std(dim=0, unbiased=False)\n",
    "            stats.append(stat_embed)\n",
    "        graph_embedding = torch.cat(stats, dim=1)\n",
    "        return self.mlp(graph_embedding)\n",
    "\n",
    "class GINNet(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 num_layers=2, num_readout_layers=2, method=\"sum\", drop_prob=0.2):\n",
    "        super(GINNet, self).__init__()\n",
    "        self.input_mlp = MLP(in_channels, hidden_channels)\n",
    "        # self.stn = STN3dFlexible() ########0421\n",
    "        self.layers = nn.ModuleList([\n",
    "            CustomGINConv(MLP(hidden_channels, hidden_channels))\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.readout = ReadoutWithMLP(\n",
    "            hidden_channels, out_channels,\n",
    "            num_hidden_layers=num_readout_layers,\n",
    "            method=method\n",
    "        )\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch_idx, frame_idx=None):\n",
    "        if self.training:\n",
    "            # ðŸ”¹ ì „ì²´ í¬ì¸íŠ¸ ì¤‘ ì¼ë¶€ ë“œë¡­ (í™•ë¥  ê¸°ë°˜)\n",
    "            mask = torch.rand(x.size(0), device=x.device) > self.drop_prob\n",
    "        else:\n",
    "            mask = torch.ones(x.size(0), dtype=torch.bool, device=x.device)\n",
    "        \n",
    "        ### STN 0421\n",
    "        # pos = x[:, :3]\n",
    "        # aligned_pos = self.stn(pos, batch_idx)\n",
    "        # x = torch.cat([aligned_pos, x[:, 3:].clone()], dim=1)  # âœ… clone() í™•ì‹¤ížˆ\n",
    "        ###\n",
    "\n",
    "        x = x * mask.unsqueeze(1).float()\n",
    "        x = self.input_mlp(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index, edge_weight)\n",
    "\n",
    "        return self.readout(x, batch_idx, valid_mask=mask)\n",
    "\n",
    "class GraphClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, num_hidden_layers=2, dropout_rate=0.5):\n",
    "\n",
    "        super(GraphClassifier, self).__init__()\n",
    "        hidden_dims = []\n",
    "        prev_dim = in_channels\n",
    "        for i in range(num_hidden_layers):\n",
    "            hidden_dims.append(prev_dim // 2)\n",
    "            prev_dim = prev_dim // 2  \n",
    "            if prev_dim < num_classes:  \n",
    "                break\n",
    "            \n",
    "        layers = []\n",
    "        prev_dim = in_channels\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            # layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.LayerNorm(hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = hidden_dim \n",
    "        layers.append(nn.Linear(prev_dim, num_classes))  \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, graph_embedding):\n",
    "        return self.mlp(graph_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 5-FOLD CV: Multi-Task (Action + User) with Shared Backbone\n",
    "#  - Backbone: GINBackbone\n",
    "#  - Action head: TemporalGatedReadout + Classifier\n",
    "#  - User   head: StatsRFFReadout     + Classifier\n",
    "#  - Stratified K-fold on ACTION labels \n",
    "# ============================================\n",
    "import os, time, copy, math, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "from torch_geometric.loader import DataLoader as PYGLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def normalize_time_per_graph(time_steps, batch):\n",
    "    device = batch.device\n",
    "    t = time_steps.to(device).float()\n",
    "    out = torch.zeros_like(t, device=device)\n",
    "    B = int(batch.max().item()) + 1 if batch.numel() else 1\n",
    "    for b in range(B):\n",
    "        m = (batch == b)\n",
    "        if m.any():\n",
    "            tb = t[m]; mn, mx = tb.min(), tb.max()\n",
    "            out[m] = (tb - mn) / (mx - mn + 1e-6)\n",
    "    return out.unsqueeze(1)  # [N,1]\n",
    "\n",
    "def per_graph_softmax(scores: torch.Tensor, batch: torch.Tensor, topk_ratio: float = None) -> torch.Tensor:\n",
    "    out = torch.zeros_like(scores)\n",
    "    B = int(batch.max().item()) + 1 if batch.numel() else 1\n",
    "    for b in range(B):\n",
    "        m = (batch == b)\n",
    "        s = scores[m]\n",
    "        if s.numel() == 0:\n",
    "            continue\n",
    "        if topk_ratio is not None and 0.0 < topk_ratio < 1.0:\n",
    "            s1 = s.squeeze(1)\n",
    "            k = max(1, int(math.ceil(topk_ratio * s1.numel())))\n",
    "            topk_idx = torch.topk(s1, k).indices\n",
    "            mask1 = torch.zeros_like(s1, dtype=torch.bool); mask1[topk_idx] = True\n",
    "            s_sel  = s1[mask1]\n",
    "            s_norm = torch.softmax(s_sel, dim=0)\n",
    "            tmp1 = torch.zeros_like(s1); tmp1[mask1] = s_norm\n",
    "            out[m] = tmp1.unsqueeze(1)\n",
    "        else:\n",
    "            out[m] = torch.softmax(s, dim=0)\n",
    "    return out\n",
    "\n",
    "# ---------- Backbone ----------\n",
    "class GINBackbone(nn.Module):\n",
    "    def __init__(self, in_channels=4, hidden_channels=64, num_layers=2, drop_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.input_mlp = MLP(in_channels, hidden_channels)\n",
    "        self.layers = nn.ModuleList([CustomGINConv(MLP(hidden_channels, hidden_channels))\n",
    "                                     for _ in range(num_layers)])\n",
    "        self.drop_prob = drop_prob\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        if self.training and self.drop_prob > 0.0:\n",
    "            mask = (torch.rand(x.size(0), device=x.device) > self.drop_prob)\n",
    "            x = x * mask.unsqueeze(1).float()\n",
    "        x = self.input_mlp(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index, edge_weight)\n",
    "        return x\n",
    "\n",
    "# ---------- Readouts ----------\n",
    "class TemporalGatedReadout(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, topk_ratio=0.25):\n",
    "        super().__init__()\n",
    "        self.wh = nn.Linear(in_dim, in_dim)\n",
    "        self.wt = nn.Linear(1, in_dim)\n",
    "        self.score = nn.Linear(in_dim, 1)\n",
    "        self.topk_ratio = topk_ratio\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(in_dim * 3, out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "        )\n",
    "    def forward(self, node_h, batch, time_steps):\n",
    "        t_norm = normalize_time_per_graph(time_steps, batch)\n",
    "        s = torch.tanh(self.wh(node_h) + self.wt(t_norm))\n",
    "        scores = self.score(s)\n",
    "        alpha = per_graph_softmax(scores, batch, self.topk_ratio)\n",
    "        attn_pool = global_add_pool(alpha * node_h, batch)\n",
    "        mean_pool = global_mean_pool(node_h, batch)\n",
    "        max_pool  = global_max_pool(node_h, batch)\n",
    "        return self.proj(torch.cat([attn_pool, mean_pool, max_pool], dim=1))\n",
    "\n",
    "class StatsRFFReadout(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rff_dim=64):\n",
    "        super().__init__()\n",
    "        self.B = nn.Parameter(torch.randn(in_dim, rff_dim) * 0.5)\n",
    "        self.b = nn.Parameter(torch.rand(rff_dim) * 2 * math.pi)\n",
    "        self.scale = math.sqrt(2.0 / rff_dim)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(in_dim * 2 + rff_dim, out_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "        )\n",
    "    def forward(self, node_h, batch, time_steps=None):\n",
    "        mu  = global_mean_pool(node_h, batch)\n",
    "        xc  = node_h - mu[batch]\n",
    "        var = global_mean_pool(xc * xc, batch)\n",
    "        std = torch.sqrt(var + 1e-6)\n",
    "        z = torch.cos(node_h @ self.B + self.b) * self.scale\n",
    "        from torch_geometric.nn import global_mean_pool as gmp\n",
    "        kme = gmp(z, batch)\n",
    "        return self.proj(torch.cat([mu, std, kme], dim=1))\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, in_dim=4, h_dim=64, r_dim=1024, num_layers=2,\n",
    "                 drop_prob=0.0, topk_ratio=0.25, rff_dim=64,\n",
    "                 num_classes_act=21, num_classes_usr=41):\n",
    "        super().__init__()\n",
    "        self.backbone   = GINBackbone(in_dim, h_dim, num_layers=num_layers, drop_prob=drop_prob)\n",
    "        self.ro_action  = TemporalGatedReadout(h_dim, r_dim, topk_ratio=topk_ratio)\n",
    "        self.ro_user    = StatsRFFReadout(h_dim, r_dim, rff_dim=rff_dim)\n",
    "        self.cls_action = GraphClassifier(in_channels=r_dim, num_classes=num_classes_act, num_hidden_layers=2, dropout_rate=0.5)\n",
    "        self.cls_user   = GraphClassifier(in_channels=r_dim, num_classes=num_classes_usr, num_hidden_layers=2, dropout_rate=0.5)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch, time_steps=None):\n",
    "        h = self.backbone(x, edge_index, edge_weight)\n",
    "        g_act = self.ro_action(h, batch, time_steps)\n",
    "        g_usr = self.ro_user(h, batch, time_steps)\n",
    "        logits_act = self.cls_action(g_act)\n",
    "        logits_usr = self.cls_user(g_usr)\n",
    "        return {'act': logits_act, 'user': logits_usr}\n",
    "\n",
    "    def forward_act(self, x, edge_index, edge_weight, batch, time_steps=None):\n",
    "        h = self.backbone(x, edge_index, edge_weight)\n",
    "        g = self.ro_action(h, batch, time_steps)\n",
    "        return self.cls_action(g)\n",
    "\n",
    "    def forward_user(self, x, edge_index, edge_weight, batch, time_steps=None):\n",
    "        h = self.backbone(x, edge_index, edge_weight)\n",
    "        g = self.ro_user(h, batch, time_steps)\n",
    "        return self.cls_user(g)\n",
    "\n",
    "# ---------- Dataset build ----------\n",
    "def build_multitask_graphs_all(graphs, g_labels, u_labels, missing_user=-100, seed=42):\n",
    "    set_seed(seed)\n",
    "    assert len(graphs) == len(g_labels) == len(u_labels), \"ê¸¸ì´ ì•ˆ ë§žìŒ\"\n",
    "    gs = []\n",
    "    for g, ya, yu in zip(graphs, g_labels, u_labels):\n",
    "        gg = copy.deepcopy(g)\n",
    "        gg.y_act  = torch.tensor(int(ya), dtype=torch.long)\n",
    "        yu_val = int(yu) if yu is not None else missing_user\n",
    "        gg.y_user = torch.tensor(yu_val, dtype=torch.long)\n",
    "        gs.append(gg)\n",
    "    return gs\n",
    "\n",
    "def make_loaders(train_ds, val_ds, test_ds, bs=32, workers=0):\n",
    "    return (\n",
    "        PYGLoader(train_ds, batch_size=bs, shuffle=True,  num_workers=workers),\n",
    "        PYGLoader(val_ds,   batch_size=bs, shuffle=False, num_workers=workers),\n",
    "        PYGLoader(test_ds,  batch_size=bs, shuffle=False, num_workers=workers),\n",
    "    )\n",
    "\n",
    "# ---------- Stratified K-fold (on action labels) ----------\n",
    "def stratified_kfold_indices(y, k=5, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    folds = [[] for _ in range(k)]\n",
    "    for c in np.unique(y):\n",
    "        idx_c = np.where(y == c)[0]\n",
    "        rng.shuffle(idx_c)\n",
    "        for i, idx in enumerate(idx_c):\n",
    "            folds[i % k].append(int(idx))\n",
    "    return [np.array(f, dtype=np.int64) for f in folds]\n",
    "\n",
    "def stratified_train_val_split(indices, y, val_ratio=0.1, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    y_pool = y[indices]\n",
    "    train_idx, val_idx = [], []\n",
    "    for c in np.unique(y_pool):\n",
    "        idx_c = indices[y_pool == c].copy()\n",
    "        rng.shuffle(idx_c)\n",
    "        n_val = max(1, int(len(idx_c) * val_ratio))\n",
    "        val_idx.extend(idx_c[:n_val].tolist())\n",
    "        train_idx.extend(idx_c[n_val:].tolist())\n",
    "    rng.shuffle(train_idx); rng.shuffle(val_idx)\n",
    "    return np.array(train_idx, dtype=np.int64), np.array(val_idx, dtype=np.int64)\n",
    "\n",
    "# ---------- Eval helper ----------\n",
    "@torch.no_grad()\n",
    "def eval_multitask(model, loader, missing_user=-100):\n",
    "    model.eval()\n",
    "    vc_a = vt_a = 0\n",
    "    vc_u = vt_u = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        y_act  = batch.y_act.view(-1)\n",
    "        y_user = batch.y_user.view(-1)\n",
    "\n",
    "        x, ei = batch.x, batch.edge_index\n",
    "        ew = batch.edge_weight if hasattr(batch,'edge_weight') and batch.edge_weight is not None \\\n",
    "             else torch.ones(ei.size(1), device=x.device)\n",
    "        bidx   = batch.batch\n",
    "        tsteps = batch.time_steps if hasattr(batch,'time_steps') else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "\n",
    "        outs = model(x, ei, ew, bidx, tsteps)\n",
    "        la, lu = outs['act'], outs['user']\n",
    "\n",
    "        pa = la.argmax(1)\n",
    "        vc_a += (pa == y_act).sum().item()\n",
    "        vt_a += y_act.size(0)\n",
    "\n",
    "        mu = (y_user != missing_user)\n",
    "        if mu.any():\n",
    "            pu = lu.argmax(1)\n",
    "            vc_u += (pu[mu] == y_user[mu]).sum().item()\n",
    "            vt_u += int(mu.sum().item())\n",
    "\n",
    "    acc_a = vc_a / max(vt_a, 1)\n",
    "    acc_u = (vc_u / max(vt_u, 1)) if vt_u > 0 else 0.0\n",
    "    return acc_a, acc_u\n",
    "\n",
    "# ---------- Train one fold (with early stop on combo) ----------\n",
    "def train_one_fold(train_loader, val_loader, test_loader,\n",
    "                   epochs=90, lr=5e-4, max_lr=3e-3, lambda_user=1.0,\n",
    "                   h_dim=64, r_dim=1024, num_layers=2,\n",
    "                   topk_ratio=0.25, rff_dim=64,\n",
    "                   num_classes_act=49, num_classes_usr=11,\n",
    "                   missing_user=-100,\n",
    "                   patience=12, min_delta=1e-4, warmup_epochs=5,\n",
    "                   ckpt_path=\"prop_multitask_fold0.pth\",\n",
    "                   seed=42):\n",
    "    set_seed(seed)\n",
    "\n",
    "    model = MultiTaskModel(\n",
    "        in_dim=4, h_dim=h_dim, r_dim=r_dim, num_layers=num_layers,\n",
    "        topk_ratio=topk_ratio, rff_dim=rff_dim,\n",
    "        num_classes_act=num_classes_act, num_classes_usr=num_classes_usr\n",
    "    ).to(device)\n",
    "\n",
    "    opt   = Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    sched = OneCycleLR(opt, max_lr=max_lr, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "    ce    = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    best_combo = -1.0\n",
    "    best_state = None\n",
    "    no_improve = 0\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            y_act  = batch.y_act.view(-1)\n",
    "            y_user = batch.y_user.view(-1)\n",
    "\n",
    "            x, ei = batch.x, batch.edge_index\n",
    "            ew = batch.edge_weight if hasattr(batch,'edge_weight') and batch.edge_weight is not None \\\n",
    "                 else torch.ones(ei.size(1), device=x.device)\n",
    "            bidx   = batch.batch\n",
    "            tsteps = batch.time_steps if hasattr(batch,'time_steps') else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "\n",
    "            outs = model(x, ei, ew, bidx, tsteps)\n",
    "            logits_a, logits_u = outs['act'], outs['user']\n",
    "\n",
    "            loss_a = ce(logits_a, y_act)\n",
    "\n",
    "            mask_u = (y_user != missing_user)\n",
    "            if mask_u.any():\n",
    "                loss_u = ce(logits_u[mask_u], y_user[mask_u])\n",
    "            else:\n",
    "                loss_u = torch.tensor(0.0, device=device)\n",
    "\n",
    "            loss = loss_a + lambda_user * loss_u\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            sched.step()\n",
    "\n",
    "        # val\n",
    "        val_acc_a, val_acc_u = eval_multitask(model, val_loader, missing_user=missing_user)\n",
    "        combo = 0.5 * (val_acc_a + val_acc_u)\n",
    "\n",
    "        print(f\"[FOLD] Ep {ep+1:02d} | Val A:{val_acc_a:.4f} U:{val_acc_u:.4f} | Combo:{combo:.4f}\")\n",
    "\n",
    "        if (combo - best_combo) > min_delta:\n",
    "            best_combo = combo\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_state, ckpt_path)\n",
    "            no_improve = 0\n",
    "            print(\"âœ… Saved:\", ckpt_path)\n",
    "        else:\n",
    "            if (ep + 1) > warmup_epochs:\n",
    "                no_improve += 1\n",
    "\n",
    "        if (ep + 1) > warmup_epochs and no_improve >= patience:\n",
    "            print(f\"â¹ï¸ Early stop (patience={patience})\")\n",
    "            break\n",
    "\n",
    "    # test (best)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    test_acc_a, test_acc_u = eval_multitask(model, test_loader, missing_user=missing_user)\n",
    "    print(f\"ðŸ”¥ [FOLD] Test Acc â€” Action: {test_acc_a:.4f} | User: {test_acc_u:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"best_combo\": float(best_combo),\n",
    "        \"test_acc_action\": float(test_acc_a),\n",
    "        \"test_acc_user\": float(test_acc_u),\n",
    "        \"ckpt\": ckpt_path\n",
    "    }\n",
    "\n",
    "# ---------- 5-fold CV wrapper ----------\n",
    "def train_multitask_5fold(\n",
    "    k_folds=5,\n",
    "    epochs=90, lr=5e-4, max_lr=3e-3, lambda_user=1.0,\n",
    "    h_dim=64, r_dim=1024, num_layers=2,\n",
    "    bs=32, workers=0,\n",
    "    seed=42,\n",
    "    topk_ratio=0.25, rff_dim=64,\n",
    "    num_classes_act=21, num_classes_usr=41,\n",
    "    missing_user=-100,\n",
    "    val_ratio=0.1,\n",
    "    fold_seed=42, val_seed=123,\n",
    "    patience=12, min_delta=1e-4, warmup_epochs=5,\n",
    "    ckpt_dir=\"./ckpt_multitask_5fold\",\n",
    "):\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    set_seed(seed)\n",
    "\n",
    "    # 0) full dataset (labels embedded)\n",
    "    gs = build_multitask_graphs_all(\n",
    "        filtered_graphs, filtered_g_labels, filtered_u_labels,\n",
    "        missing_user=missing_user, seed=seed\n",
    "    )\n",
    "\n",
    "    # 1) folds stratified by ACTION labels\n",
    "    y_act_all = np.array([int(g.y_act.item()) for g in gs], dtype=np.int64)\n",
    "    folds = stratified_kfold_indices(y_act_all, k=k_folds, seed=fold_seed)\n",
    "\n",
    "    all_idx = np.arange(len(gs), dtype=np.int64)\n",
    "\n",
    "    fold_results = []\n",
    "    for fold in range(k_folds):\n",
    "        test_idx = folds[fold]\n",
    "        trainval_idx = np.setdiff1d(all_idx, test_idx, assume_unique=False)\n",
    "\n",
    "        # train/val split stratified by ACTION within trainval\n",
    "        train_idx, val_idx = stratified_train_val_split(\n",
    "            trainval_idx, y_act_all, val_ratio=val_ratio, seed=val_seed + fold\n",
    "        )\n",
    "\n",
    "        train_ds = [gs[i] for i in train_idx]\n",
    "        val_ds   = [gs[i] for i in val_idx]\n",
    "        test_ds  = [gs[i] for i in test_idx]\n",
    "\n",
    "        train_loader, val_loader, test_loader = make_loaders(train_ds, val_ds, test_ds, bs=bs, workers=workers)\n",
    "\n",
    "        ckpt_path = os.path.join(ckpt_dir, f\"prop_multitask_shared_backbone_fold{fold}.pth\")\n",
    "\n",
    "        print(f\"\\n==================== FOLD {fold}/{k_folds-1} ====================\")\n",
    "        print(f\"[SPLIT] train/val/test = {len(train_ds)}/{len(val_ds)}/{len(test_ds)} | bs={bs}\")\n",
    "\n",
    "        r = train_one_fold(\n",
    "            train_loader, val_loader, test_loader,\n",
    "            epochs=epochs, lr=lr, max_lr=max_lr, lambda_user=lambda_user,\n",
    "            h_dim=h_dim, r_dim=r_dim, num_layers=num_layers,\n",
    "            topk_ratio=topk_ratio, rff_dim=rff_dim,\n",
    "            num_classes_act=num_classes_act, num_classes_usr=num_classes_usr,\n",
    "            missing_user=missing_user,\n",
    "            patience=patience, min_delta=min_delta, warmup_epochs=warmup_epochs,\n",
    "            ckpt_path=ckpt_path,\n",
    "            seed=seed + fold\n",
    "        )\n",
    "\n",
    "        r.update({\n",
    "            \"fold\": int(fold),\n",
    "            \"sizes\": {\"train\": int(len(train_ds)), \"val\": int(len(val_ds)), \"test\": int(len(test_ds))}\n",
    "        })\n",
    "        fold_results.append(r)\n",
    "\n",
    "    # summary\n",
    "    a_list = [r[\"test_acc_action\"] for r in fold_results]\n",
    "    u_list = [r[\"test_acc_user\"] for r in fold_results]\n",
    "    a_mean, a_std = float(np.mean(a_list)), float(np.std(a_list))\n",
    "    u_mean, u_std = float(np.mean(u_list)), float(np.std(u_list))\n",
    "\n",
    "    print(\"\\n==================== 5-FOLD SUMMARY ====================\")\n",
    "    for r in fold_results:\n",
    "        sz = r[\"sizes\"]\n",
    "        print(f\"fold{r['fold']} | TestA {r['test_acc_action']:.4f} | TestU {r['test_acc_user']:.4f} | \"\n",
    "              f\"train/val/test={sz['train']}/{sz['val']}/{sz['test']} | ckpt={r['ckpt']}\")\n",
    "    print(f\"MEANÂ±STD Action = {a_mean:.4f} Â± {a_std:.4f}\")\n",
    "    print(f\"MEANÂ±STD User   = {u_mean:.4f} Â± {u_std:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"folds\": fold_results,\n",
    "        \"mean_action\": a_mean, \"std_action\": a_std,\n",
    "        \"mean_user\": u_mean, \"std_user\": u_std,\n",
    "        \"ckpt_dir\": ckpt_dir\n",
    "    }\n",
    "\n",
    "set_seed(42)\n",
    "res_cv = train_multitask_5fold(\n",
    "    k_folds=5,\n",
    "    epochs=100, lr=5e-4, max_lr=1e-3, lambda_user=1.0,\n",
    "    h_dim=64, r_dim=1024, num_layers=2,\n",
    "    bs=16, workers=0,\n",
    "    seed=42,\n",
    "    topk_ratio=0.25, rff_dim=64,\n",
    "    num_classes_act=21, num_classes_usr=41,\n",
    "    missing_user=-100,\n",
    "    val_ratio=0.1,\n",
    "    fold_seed=42, val_seed=123,\n",
    "    patience=12, min_delta=1e-4, warmup_epochs=5,\n",
    "    ckpt_dir=\"./ckpt_multitask_5fold\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n===== [MT-5F] Summary =====\")\n",
    "print(f\"Action meanÂ±std = {res_cv['mean_action']:.4f} Â± {res_cv['std_action']:.4f}\")\n",
    "print(f\"User   meanÂ±std = {res_cv['mean_user']:.4f} Â± {res_cv['std_user']:.4f}\")\n",
    "print(\"CKPT dir:\", res_cv[\"ckpt_dir\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3222a3a4",
   "metadata": {},
   "source": [
    "model profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TEST/PROFILE CELL: MultiTask 5-Fold (Action+User) CKPT -> ACC + SIZE/PARAMS/FLOPs/LAT\n",
    "#  - Loads each fold checkpoint from ckpt_dir\n",
    "#  - Rebuilds same folds (stratified on ACTION)\n",
    "#  - Reports per-fold TestAcc(Action/User), ckpt size, params, FLOPs (if thop works), latency (ms)\n",
    "#  - Copy & Paste ready\n",
    "# ============================================\n",
    "import os, time, math, copy, numpy as np, torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from torch_geometric.loader import DataLoader as PYGLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------------------------\n",
    "# MUST MATCH TRAIN SETTINGS\n",
    "# ---------------------------\n",
    "CKPT_DIR = \"./ckpt_multitask_5fold\"\n",
    "K_FOLDS  = 5\n",
    "BS_TEST  = 1          # profiling/eval batch size (can differ from train)\n",
    "WORKERS  = 0\n",
    "MISSING_USER = -100\n",
    "\n",
    "# model hyperparams must match train\n",
    "IN_DIM = 4\n",
    "H_DIM  = 64\n",
    "R_DIM  = 1024\n",
    "NUM_LAYERS = 2\n",
    "TOPK_RATIO = 0.25\n",
    "RFF_DIM = 64\n",
    "\n",
    "# If you changed these to \"auto\" in training, set them here too (recommended)\n",
    "NUM_CLASSES_ACT = 21\n",
    "NUM_CLASSES_USR = 41\n",
    "\n",
    "# thop settings\n",
    "THOP_WARMUP_BATCHES = 1\n",
    "\n",
    "# latency settings (forward only)\n",
    "LAT_WARMUP = 30\n",
    "LAT_RUNS   = 200\n",
    "\n",
    "# ---------------------------\n",
    "# Seed / folds (same as train)\n",
    "# ---------------------------\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def stratified_kfold_indices(y, k=5, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y, dtype=np.int64)\n",
    "    folds = [[] for _ in range(k)]\n",
    "    for c in np.unique(y):\n",
    "        idx_c = np.where(y == c)[0]\n",
    "        rng.shuffle(idx_c)\n",
    "        for i, idx in enumerate(idx_c):\n",
    "            folds[i % k].append(int(idx))\n",
    "    return [np.array(f, dtype=np.int64) for f in folds]\n",
    "\n",
    "def stratified_train_val_split(indices, y, val_ratio=0.1, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    y_pool = y[indices]\n",
    "    train_idx, val_idx = [], []\n",
    "    for c in np.unique(y_pool):\n",
    "        idx_c = indices[y_pool == c].copy()\n",
    "        rng.shuffle(idx_c)\n",
    "        n_val = max(1, int(len(idx_c) * val_ratio))\n",
    "        val_idx.extend(idx_c[:n_val].tolist())\n",
    "        train_idx.extend(idx_c[n_val:].tolist())\n",
    "    rng.shuffle(train_idx); rng.shuffle(val_idx)\n",
    "    return np.array(train_idx, dtype=np.int64), np.array(val_idx, dtype=np.int64)\n",
    "\n",
    "# ---------------------------\n",
    "# (Re)build dataset with labels embedded exactly like train\n",
    "# ---------------------------\n",
    "def build_multitask_graphs_all(graphs, g_labels, u_labels, missing_user=-100, seed=42):\n",
    "    set_seed(seed)\n",
    "    assert len(graphs) == len(g_labels) == len(u_labels), \"length mismatch\"\n",
    "    gs = []\n",
    "    for g, ya, yu in zip(graphs, g_labels, u_labels):\n",
    "        gg = copy.deepcopy(g)\n",
    "        gg.y_act  = torch.tensor(int(ya), dtype=torch.long)\n",
    "        yu_val = int(yu) if (yu is not None) else missing_user\n",
    "        gg.y_user = torch.tensor(yu_val, dtype=torch.long)\n",
    "        gs.append(gg)\n",
    "    return gs\n",
    "\n",
    "def make_loader(ds, bs=64, workers=0, shuffle=False):\n",
    "    return PYGLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=workers)\n",
    "\n",
    "# ---------------------------\n",
    "# Model (must already be defined in previous cell)\n",
    "#   - GINBackbone, TemporalGatedReadout, StatsRFFReadout, GraphClassifier, MultiTaskModel\n",
    "# ---------------------------\n",
    "def build_model(num_classes_act, num_classes_usr):\n",
    "    model = MultiTaskModel(\n",
    "        in_dim=IN_DIM, h_dim=H_DIM, r_dim=R_DIM, num_layers=NUM_LAYERS,\n",
    "        topk_ratio=TOPK_RATIO, rff_dim=RFF_DIM,\n",
    "        num_classes_act=num_classes_act,\n",
    "        num_classes_usr=num_classes_usr\n",
    "    ).to(device)\n",
    "    return model\n",
    "\n",
    "def load_state_1gpu(model, path):\n",
    "    sd = torch.load(path, map_location=device)\n",
    "    if isinstance(sd, dict) and any(k.startswith(\"module.\") for k in sd.keys()):\n",
    "        sd = OrderedDict((k.replace(\"module.\", \"\"), v) for k, v in sd.items())\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# ---------------------------\n",
    "# Accuracy eval (Action/User on test split)\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def eval_multitask(model, loader, missing_user=-100):\n",
    "    model.eval()\n",
    "    vc_a = vt_a = 0\n",
    "    vc_u = vt_u = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        y_act  = batch.y_act.view(-1)\n",
    "        y_user = batch.y_user.view(-1)\n",
    "\n",
    "        x, ei = batch.x, batch.edge_index\n",
    "        ew = batch.edge_weight if (hasattr(batch, \"edge_weight\") and batch.edge_weight is not None) \\\n",
    "             else torch.ones(ei.size(1), device=x.device)\n",
    "        bidx   = batch.batch\n",
    "        tsteps = batch.time_steps if hasattr(batch, \"time_steps\") else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "\n",
    "        outs = model(x, ei, ew, bidx, tsteps)\n",
    "        la, lu = outs[\"act\"], outs[\"user\"]\n",
    "\n",
    "        pa = la.argmax(1)\n",
    "        vc_a += (pa == y_act).sum().item()\n",
    "        vt_a += y_act.numel()\n",
    "\n",
    "        mu = (y_user != missing_user)\n",
    "        if mu.any():\n",
    "            pu = lu.argmax(1)\n",
    "            vc_u += (pu[mu] == y_user[mu]).sum().item()\n",
    "            vt_u += int(mu.sum().item())\n",
    "\n",
    "    acc_a = vc_a / max(vt_a, 1)\n",
    "    acc_u = (vc_u / max(vt_u, 1)) if vt_u > 0 else 0.0\n",
    "    return float(acc_a), float(acc_u)\n",
    "\n",
    "# ---------------------------\n",
    "# Size / Params / FLOPs / Latency\n",
    "# ---------------------------\n",
    "def get_model_size_mb(path):\n",
    "    return os.path.getsize(path) / (1024 * 1024)\n",
    "\n",
    "def count_params_m(model):\n",
    "    return sum(p.numel() for p in model.parameters()) / 1e6\n",
    "\n",
    "def try_get_flops_m(model, example_batch):\n",
    "    \"\"\"\n",
    "    Returns FLOPs(M) (not MACs) for one forward pass of MultiTaskModel.\n",
    "    thop may fail depending on ops. If fails -> None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from thop import profile\n",
    "        batch = example_batch.to(device)\n",
    "        x, ei = batch.x, batch.edge_index\n",
    "        ew = batch.edge_weight if (hasattr(batch, \"edge_weight\") and batch.edge_weight is not None) \\\n",
    "             else torch.ones(ei.size(1), device=x.device)\n",
    "        bidx = batch.batch\n",
    "        tsteps = batch.time_steps if hasattr(batch, \"time_steps\") else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "\n",
    "        # thop expects plain tensors as inputs\n",
    "        macs, _ = profile(model, inputs=(x, ei, ew, bidx, tsteps), verbose=False)\n",
    "        flops = macs * 2.0\n",
    "        return float(flops / 1e6)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "@torch.inference_mode()\n",
    "def measure_latency_ms(model, example_batch, warmup=30, runs=200):\n",
    "    batch = example_batch.to(device)\n",
    "    x, ei = batch.x, batch.edge_index\n",
    "    ew = batch.edge_weight if (hasattr(batch, \"edge_weight\") and batch.edge_weight is not None) \\\n",
    "         else torch.ones(ei.size(1), device=x.device)\n",
    "    bidx = batch.batch\n",
    "    tsteps = batch.time_steps if hasattr(batch, \"time_steps\") else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = model(x, ei, ew, bidx, tsteps)\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(runs):\n",
    "        _ = model(x, ei, ew, bidx, tsteps)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t1 = time.perf_counter()\n",
    "    return (t1 - t0) * 1000.0 / runs\n",
    "\n",
    "def print_table(rows, title=\"MULTITASK 5F (TEST/PROFILE)\"):\n",
    "    print(f\"\\n==================== {title} ====================\")\n",
    "    hdr = f\"{'Fold':>4} {'AccA':>8} {'AccU':>8} {'Size(MB)':>10} {'FLOPs(M)':>10} {'Params(M)':>10} {'Lat(ms)':>10}\"\n",
    "    print(hdr)\n",
    "    print(\"-\" * len(hdr))\n",
    "    for r in rows:\n",
    "        fold, accA, accU, size_mb, flops_m, params_m, lat_ms = r\n",
    "        flops_str = f\"{flops_m:10.2f}\" if flops_m is not None else f\"{'n/a':>10}\"\n",
    "        print(f\"{fold:>4d} {accA:8.4f} {accU:8.4f} {size_mb:10.2f} {flops_str} {params_m:10.2f} {lat_ms:10.2f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN: reconstruct folds + load ckpts + profile\n",
    "#   Requires these globals from your training cell:\n",
    "#     filtered_graphs, filtered_g_labels, filtered_u_labels\n",
    "# ---------------------------\n",
    "assert \"filtered_graphs\" in globals() and \"filtered_g_labels\" in globals() and \"filtered_u_labels\" in globals(), \\\n",
    "    \"í•„ìš”: filtered_graphs / filtered_g_labels / filtered_u_labels (í•™ìŠµ ì…€ì—ì„œ ìƒì„±ëœ ê²ƒ)\"\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# dataset with labels embedded\n",
    "gs = build_multitask_graphs_all(\n",
    "    filtered_graphs, filtered_g_labels, filtered_u_labels,\n",
    "    missing_user=MISSING_USER, seed=42\n",
    ")\n",
    "\n",
    "# folds stratified by action\n",
    "y_act_all = np.array([int(g.y_act.item()) for g in gs], dtype=np.int64)\n",
    "folds = stratified_kfold_indices(y_act_all, k=K_FOLDS, seed=42)\n",
    "\n",
    "all_idx = np.arange(len(gs), dtype=np.int64)\n",
    "\n",
    "rows = []\n",
    "accA_list, accU_list = [], []\n",
    "\n",
    "for fold in range(K_FOLDS):\n",
    "    ckpt_path = os.path.join(CKPT_DIR, f\"prop_multitask_shared_backbone_fold{fold}.pth\")\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        raise FileNotFoundError(f\"Missing ckpt: {ckpt_path}\")\n",
    "\n",
    "    test_idx = folds[fold]\n",
    "    test_ds  = [gs[i] for i in test_idx]\n",
    "    test_loader = make_loader(test_ds, bs=BS_TEST, workers=WORKERS, shuffle=False)\n",
    "\n",
    "    # example batch for FLOPs/lat\n",
    "    example_batch = next(iter(test_loader))\n",
    "    # (optional) warmup batch for CUDA init\n",
    "    _ = example_batch.to(device)\n",
    "\n",
    "    model = build_model(NUM_CLASSES_ACT, NUM_CLASSES_USR)\n",
    "    model = load_state_1gpu(model, ckpt_path)\n",
    "\n",
    "    # accuracy\n",
    "    accA, accU = eval_multitask(model, test_loader, missing_user=MISSING_USER)\n",
    "\n",
    "    # size/params/flops/lat\n",
    "    size_mb  = get_model_size_mb(ckpt_path)\n",
    "    params_m = count_params_m(model)\n",
    "    flops_m  = try_get_flops_m(model, example_batch)\n",
    "    lat_ms   = measure_latency_ms(model, example_batch, warmup=LAT_WARMUP, runs=LAT_RUNS)\n",
    "\n",
    "    rows.append((fold+1, accA, accU, size_mb, flops_m, params_m, lat_ms))\n",
    "    accA_list.append(accA); accU_list.append(accU)\n",
    "\n",
    "print_table(rows)\n",
    "\n",
    "print(\"\\n===== SUMMARY =====\")\n",
    "print(f\"Action: meanÂ±std = {float(np.mean(accA_list)):.4f} Â± {float(np.std(accA_list)):.4f}\")\n",
    "print(f\"User  : meanÂ±std = {float(np.mean(accU_list)):.4f} Â± {float(np.std(accU_list)):.4f}\")\n",
    "print(\"CKPT dir:\", CKPT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
